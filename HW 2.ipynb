{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e41855-1123-408e-87ab-1aa35410f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation, test pytesseract\n",
    "from PIL import Image\n",
    "import pytesseract #pip install pytesseract first\n",
    "\n",
    "# Load an image using Pillow (PIL)\n",
    "image = Image.open(r'C:\\Users\\FeiFei\\Pictures\\12.jpg')\n",
    "\n",
    "# Perform OCR on the image\n",
    "text = pytesseract.image_to_string(image)\n",
    "\n",
    "print(text)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b112db75-77a1-4340-9873-875392c3e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m pip install feedparser requests trafilatura pytesseract playwright pillow\n",
    "# python -m playwright install\n",
    "\n",
    "# Step 1 â€” Install required packages\n",
    "# !pip install requests beautifulsoup4 trafilatura pytesseract pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed494c2-8ca5-422f-bc6e-b541c81b8214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tesseract version: 5.5.0.20241111\n"
     ]
    }
   ],
   "source": [
    "# Step 2 â€” Set up and test Tesseract path (Windows only)\n",
    "import pytesseract\n",
    "\n",
    "# ðŸ‘‡ Adjust this path if your Tesseract is elsewhere\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\FeiFei\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Test it\n",
    "print(\"âœ… Tesseract version:\", pytesseract.get_tesseract_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa65ccad-ef96-407e-87ee-a3cbc413aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 â€” Import libraries and define scraper functions\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura\n",
    "from tqdm import tqdm\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import json\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "BASE_URL = \"https://arxiv.org\"\n",
    "CATEGORY = \"cs.CL\"   # ðŸ‘ˆ Change this to any subcategory (e.g. cs.LG, math.ST)\n",
    "N_PAPERS = 50         # You can increase later (e.g. 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c16147-0f01-49a3-a2b7-1d00fc03ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 â€” Helper functions\n",
    "\n",
    "def fetch_arxiv_links(category=CATEGORY, n=N_PAPERS):\n",
    "    \"\"\"Fetch latest paper abstract URLs from arXiv list page.\"\"\"\n",
    "    print(f\"ðŸ”Ž Fetching latest {n} papers from {category}...\")\n",
    "    url = f\"{BASE_URL}/list/{category}/pastweek?show={n}\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    links = []\n",
    "    for dt in soup.find_all(\"dt\"):\n",
    "        link = dt.find(\"a\", title=\"Abstract\")\n",
    "        if link:\n",
    "            links.append(BASE_URL + link[\"href\"])\n",
    "    return links\n",
    "\n",
    "\n",
    "def parse_arxiv_page(url):\n",
    "    \"\"\"Parse a single arXiv abstract page.\"\"\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    # Extract metadata\n",
    "    title = soup.find(\"h1\", class_=\"title\").get_text(strip=True).replace(\"Title:\", \"\")\n",
    "    authors = soup.find(\"div\", class_=\"authors\").get_text(strip=True).replace(\"Authors:\", \"\")\n",
    "    date = soup.find(\"div\", class_=\"dateline\").get_text(strip=True)\n",
    "\n",
    "    # Try to extract abstract text with Trafilatura\n",
    "    downloaded = trafilatura.fetch_url(url)\n",
    "    abstract_text = \"\"\n",
    "    if downloaded:\n",
    "        abstract_text = trafilatura.extract(downloaded, include_comments=False) or \"\"\n",
    "\n",
    "    # If Trafilatura fails or gives empty text, fallback to OCR\n",
    "    if not abstract_text.strip():\n",
    "        img = soup.find(\"img\")\n",
    "        if img and \"src\" in img.attrs:\n",
    "            img_url = BASE_URL + img[\"src\"]\n",
    "            img_res = requests.get(img_url)\n",
    "            image = Image.open(BytesIO(img_res.content))\n",
    "            abstract_text = pytesseract.image_to_string(image)\n",
    "\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"title\": title,\n",
    "        \"authors\": authors,\n",
    "        \"date\": date,\n",
    "        \"abstract\": abstract_text.strip()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0071761-ef48-4a34-a5c0-80a14ad05945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Fetching latest 50 papers from cs.CL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping papers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:41<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Saved 50 papers to arxiv_clean.json (149.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5 â€” Run scraper and save output\n",
    "\n",
    "links = fetch_arxiv_links()\n",
    "papers = []\n",
    "\n",
    "for link in tqdm(links, desc=\"Scraping papers\"):\n",
    "    try:\n",
    "        paper = parse_arxiv_page(link)\n",
    "        papers.append(paper)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error parsing {link}: {e}\")\n",
    "\n",
    "# Save to JSON\n",
    "output_file = \"arxiv_clean.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(papers, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "size_kb = os.path.getsize(output_file) / 1024\n",
    "print(f\"\\nðŸ“ Saved {len(papers)} papers to {output_file} ({size_kb:.1f} KB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16cf97e-97af-439d-8f7d-5211cfdc57d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goal\\n\\nYouâ€™ll take the PDFs of the same papers scraped in Task 1,\\nconvert each page to images, extract text via Tesseract OCR,\\nand save the results as .txt files under a pdf_ocr/ folder.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2\n",
    "\"\"\"Goal\n",
    "\n",
    "Youâ€™ll take the PDFs of the same papers scraped in Task 1,\n",
    "convert each page to images, extract text via Tesseract OCR,\n",
    "and save the results as .txt files under a pdf_ocr/ folder.\"\"\"\n",
    "\n",
    "# Step 1 â€” Install dependencies\n",
    "\n",
    "# !pip install pytesseract pdf2image pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e52c3427-3471-4c7b-aea1-d2936efdc4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Folders ready:\n",
      " - C:\\Users\\FeiFei\\Documents\\AI Engineer\\Homework\\Sophie_HW 2\\pdfs\n",
      " - C:\\Users\\FeiFei\\Documents\\AI Engineer\\Homework\\Sophie_HW 2\\pdf_ocr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_folder = \"pdfs\"       # folder for your PDF files\n",
    "output_folder = \"pdf_ocr\"   # output text folder\n",
    "\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Folders ready:\")\n",
    "print(\" -\", os.path.abspath(input_folder))\n",
    "print(\" -\", os.path.abspath(output_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "907f0d0f-30a6-47e4-a57a-17e0dba32663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://arxiv.org/pdf/2510.26802v1.pdf\n",
      "â¬‡ï¸ Downloading https://arxiv.org/pdf/2510.26790v1.pdf\n",
      "â¬‡ï¸ Downloading https://arxiv.org/pdf/2510.26788v1.pdf\n",
      "â¬‡ï¸ Downloading https://arxiv.org/pdf/2510.26787v1.pdf\n",
      "â¬‡ï¸ Downloading https://arxiv.org/pdf/2510.26768v1.pdf\n",
      "âœ… PDFs downloaded to: C:\\Users\\FeiFei\\Documents\\AI Engineer\\Homework\\Sophie_HW 2\\pdfs\n"
     ]
    }
   ],
   "source": [
    "# Auto-download PDFs from your Task 1 JSON\n",
    "import json, requests, os\n",
    "\n",
    "input_folder = \"pdfs\"\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "\n",
    "# Load Task 1 output\n",
    "with open(\"arxiv_clean.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers = json.load(f)\n",
    "\n",
    "for i, paper in enumerate(papers[:5], 1):  # limit to first 5 PDFs for testing\n",
    "    pdf_url = paper[\"url\"].replace(\"/abs/\", \"/pdf/\") + \".pdf\"\n",
    "    pdf_path = os.path.join(input_folder, f\"paper_{i}.pdf\")\n",
    "    print(f\"â¬‡ï¸ Downloading {pdf_url}\")\n",
    "    try:\n",
    "        r = requests.get(pdf_url)\n",
    "        with open(pdf_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed: {pdf_url} -> {e}\")\n",
    "\n",
    "print(\"âœ… PDFs downloaded to:\", os.path.abspath(input_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8169d8ef-2960-4039-a2f0-c8d7395ce12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 â€” Configure paths\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ðŸ‘‡ Update if necessary\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\FeiFei\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n",
    "poppler_path = r\"C:\\Users\\FeiFei\\Documents\\AI Engineer\\Release-25.07.0-0\\poppler-25.07.0\\Library\\bin\"  # <-- change to your Poppler bin folder\n",
    "\n",
    "input_folder = \"pdfs\"       # Folder where your arXiv PDFs are stored\n",
    "output_folder = \"pdf_ocr\"   # Output TXT folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d67cd7fd-abc2-4eb9-8497-1b9fb855d6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Found 5 PDF(s) in C:\\Users\\FeiFei\\Documents\\AI Engineer\\Homework\\Sophie_HW 2\\pdfs:\n",
      " - paper_1.pdf\n",
      " - paper_2.pdf\n",
      " - paper_3.pdf\n",
      " - paper_4.pdf\n",
      " - paper_5.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_folder = \"pdfs\"\n",
    "pdf_files = [f for f in os.listdir(input_folder) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "print(f\"ðŸ“„ Found {len(pdf_files)} PDF(s) in {os.path.abspath(input_folder)}:\")\n",
    "for f in pdf_files:\n",
    "    print(\" -\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bae4fcc-3b5d-45fb-b349-29c411a456d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 â€” OCR function\n",
    "from PIL import Image\n",
    "\n",
    "def ocr_pdf_to_text(pdf_path, output_txt):\n",
    "    \"\"\"Convert a single PDF to text using Tesseract OCR.\"\"\"\n",
    "    text_output = []\n",
    "\n",
    "    # Convert PDF to a list of images (one per page)\n",
    "    pages = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)\n",
    "\n",
    "    for i, page in enumerate(pages, start=1):\n",
    "        text = pytesseract.image_to_string(page)\n",
    "        text_output.append(f\"\\n\\n==== Page {i} ====\\n{text}\")\n",
    "\n",
    "    # Combine pages and write to file\n",
    "    with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(text_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3620487-906e-4d08-b685-5ee5e0467f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ” OCR Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [07:49<00:00, 93.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 â€” Batch OCR for all PDFs\n",
    "pdf_files = [f for f in os.listdir(input_folder) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "for pdf in tqdm(pdf_files, desc=\"ðŸ” OCR Processing\"):\n",
    "    input_path = os.path.join(input_folder, pdf)\n",
    "    output_txt = os.path.join(output_folder, os.path.splitext(pdf)[0] + \".txt\")\n",
    "\n",
    "    try:\n",
    "        ocr_pdf_to_text(input_path, output_txt)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error on {pdf}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517512f9-0146-49d8-97ab-63fa945ea693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 â€” (Optional) Preserve layout\n",
    "text = pytesseract.image_to_string(\n",
    "    page,\n",
    "    config=\"--oem 1 --psm 1 preserve_interword_spaces=1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dca8a6-c1e9-47e5-aace-e893770211af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Task 3:Automatic Speech Recognition (ASR) with YouTube audio \n",
    "+ OCR for any embedded text in video slides, saving a .jsonl with timestamps.\n",
    "\n",
    "Task 3 Overview\n",
    "\n",
    "Download short NLP conference talk videos from YouTube (10 talks, ~3 min each).\n",
    "\n",
    "Extract audio using yt-dlp.\n",
    "\n",
    "If slides or video frames have text, extract using Tesseract OCR.\n",
    "\n",
    "Save everything to .jsonl with timestamps.\n",
    "\n",
    "Tools:\n",
    "\n",
    "yt-dlp â€” download audio/video.\n",
    "\n",
    "pytesseract â€” OCR any slides.\n",
    "\n",
    "whisper (OpenAI) â€” ASR transcription.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c60f1c1-914c-45af-a78f-b004728d4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 â€” Install dependencies\n",
    "# !pip install yt-dlp pytesseract Pillow tqdm openai-whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a3a09e-d90e-4354-8c09-1d2aceb57344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 â€” Configure paths and imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yt_dlp\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import whisper\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --------------------------\n",
    "# Folders\n",
    "video_folder = \"talks_videos\"\n",
    "audio_folder = \"talks_audio\"\n",
    "os.makedirs(video_folder, exist_ok=True)\n",
    "os.makedirs(audio_folder, exist_ok=True)\n",
    "\n",
    "# Tesseract path (Windows)\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\FeiFei\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe60bc5-9e0c-4a5b-acd4-30ba4b0cdddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=-moW9jvvMr4\n",
      "[youtube] -moW9jvvMr4: Downloading webpage\n",
      "[youtube] -moW9jvvMr4: Downloading android sdkless player API JSON\n",
      "[youtube] -moW9jvvMr4: Downloading tv client config\n",
      "[youtube] -moW9jvvMr4: Downloading tv player API JSON\n",
      "[youtube] -moW9jvvMr4: Downloading web safari player API JSON\n",
      "[youtube] -moW9jvvMr4: Downloading player c6d7bdc9-main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] -moW9jvvMr4: nsig extraction failed: Some formats may be missing\n",
      "         n = vyamxBSnjb-zZCoT ; player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] -moW9jvvMr4: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] -moW9jvvMr4: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] -moW9jvvMr4: Downloading m3u8 information\n",
      "[info] -moW9jvvMr4: Downloading 1 format(s): 251\n",
      "[download] Sleeping 4.00 seconds as required by the site...\n",
      "[download] Destination: talks_audio\\A Simple Way to Break a Bad Habit ï½œ Judson Brewer ï½œ TED.webm\n",
      "[download] 100% of    7.35MiB in 00:00:02 at 2.48MiB/s   \n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=arj7oStGLkU\n",
      "[youtube] arj7oStGLkU: Downloading webpage\n",
      "[youtube] arj7oStGLkU: Downloading android sdkless player API JSON\n",
      "[youtube] arj7oStGLkU: Downloading tv client config\n",
      "[youtube] arj7oStGLkU: Downloading tv player API JSON\n",
      "[youtube] arj7oStGLkU: Downloading web safari player API JSON\n",
      "[youtube] arj7oStGLkU: Downloading player c6d7bdc9-main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] arj7oStGLkU: nsig extraction failed: Some formats may be missing\n",
      "         n = lt43S0HxD2pCs2Fr ; player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] arj7oStGLkU: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] arj7oStGLkU: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] arj7oStGLkU: Downloading m3u8 information\n",
      "[info] arj7oStGLkU: Downloading 1 format(s): 251\n",
      "[download] Sleeping 4.00 seconds as required by the site...\n",
      "[download] Destination: talks_audio\\Inside the Mind of a Master Procrastinator ï½œ Tim Urban ï½œ TED.webm\n",
      "[download] 100% of   12.42MiB in 00:00:07 at 1.72MiB/s   \n"
     ]
    }
   ],
   "source": [
    "# Step 2 â€” Download YouTube videos / audio\n",
    "yt_urls = [\n",
    "    \"https://www.youtube.com/watch?v=-moW9jvvMr4\",\n",
    "    \"https://www.youtube.com/watch?v=arj7oStGLkU\",\n",
    "    # add up to 10 talk URLs\n",
    "]\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'outtmpl': os.path.join(audio_folder, '%(title)s.%(ext)s'),\n",
    "    'noplaylist': True,\n",
    "    'quiet': False\n",
    "}\n",
    "\n",
    "for url in yt_urls:\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5996ee-0a71-44a5-b315-a7c63b70c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talks_audio\\A Simple Way to Break a Bad Habit ï½œ Judson Brewer ï½œ TED.webm True\n",
      "talks_audio\\Inside the Mind of a Master Procrastinator ï½œ Tim Urban ï½œ TED.webm True\n",
      "talks_audio\\talk1.webm True\n",
      "talks_audio\\talk2.webm True\n"
     ]
    }
   ],
   "source": [
    "# Optional: check files\n",
    "for f in os.listdir(audio_folder):\n",
    "    if f.lower().endswith((\".mp3\", \".m4a\", \".wav\", \".webm\")):\n",
    "        path = os.path.join(audio_folder, f)\n",
    "        print(path, os.path.exists(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "361cecad-3daf-4327-8a14-813a0ad7b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talks_audio\\A Simple Way to Break a Bad Habit ï½œ Judson Brewer ï½œ TED.webm â†’ talks_audio\\talk1.webm\n",
      "talks_audio\\Inside the Mind of a Master Procrastinator ï½œ Tim Urban ï½œ TED.webm â†’ talks_audio\\talk2.webm\n"
     ]
    }
   ],
   "source": [
    "# Optional: change file name\n",
    "\n",
    "import shutil\n",
    "\n",
    "for i, f in enumerate(os.listdir(audio_folder), start=1):\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    old_path = os.path.join(audio_folder, f)\n",
    "    new_path = os.path.join(audio_folder, f\"talk{i}{ext}\")\n",
    "    shutil.move(old_path, new_path)\n",
    "    print(f\"{old_path} â†’ {new_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3106fa-b388-4331-8521-dc022fc6753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted talks_audio\\A Simple Way to Break a Bad Habit ï½œ Judson Brewer ï½œ TED.webm â†’ talks_audio\\A Simple Way to Break a Bad Habit ï½œ Judson Brewer ï½œ TED.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-121584-ge59d964a3c-20251101 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (crosstool-NG 1.28.0.1_403899e)\n",
      "  configuration: --prefix=/ffbuild/prefix --pkg-config-flags=--static --pkg-config=pkg-config --cross-prefix=x86_64-w64-mingw32- --arch=x86_64 --target-os=mingw32 --enable-gpl --enable-version3 --disable-debug --enable-shared --disable-static --disable-w32threads --enable-pthreads --enable-iconv --enable-zlib --enable-libxml2 --enable-libvmaf --enable-fontconfig --enable-libharfbuzz --enable-libfreetype --enable-libfribidi --enable-vulkan --enable-libshaderc --enable-libvorbis --disable-libxcb --disable-xlib --disable-libpulse --enable-opencl --enable-gmp --enable-lzma --enable-amf --enable-libaom --enable-libaribb24 --enable-avisynth --enable-chromaprint --enable-libdav1d --enable-libdavs2 --enable-libdvdread --enable-libdvdnav --disable-libfdk-aac --enable-ffnvcodec --enable-cuda-llvm --enable-frei0r --enable-libgme --enable-libkvazaar --enable-libaribcaption --enable-libass --enable-libbluray --enable-libjxl --enable-libmp3lame --enable-libopus --enable-libplacebo --enable-librist --enable-libssh --enable-libtheora --enable-libvpx --enable-libwebp --enable-libzmq --enable-lv2 --enable-libvpl --enable-openal --enable-liboapv --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopenmpt --enable-librav1e --enable-librubberband --enable-schannel --enable-sdl2 --enable-libsnappy --enable-libsoxr --enable-libsrt --enable-libsvtav1 --enable-libtwolame --enable-libuavs3d --disable-libdrm --enable-vaapi --enable-libvidstab --enable-libvvenc --enable-whisper --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libzimg --enable-libzvbi --extra-cflags=-DLIBTWOLAME_STATIC --extra-cxxflags= --extra-libs=-lgomp --extra-ldflags=-pthread --extra-ldexeflags= --cc=x86_64-w64-mingw32-gcc --cxx=x86_64-w64-mingw32-g++ --ar=x86_64-w64-mingw32-gcc-ar --ranlib=x86_64-w64-mingw32-gcc-ranlib --nm=x86_64-w64-mingw32-gcc-nm --extra-version=20251101\n",
      "  libavutil      60. 16.100 / 60. 16.100\n",
      "  libavcodec     62. 17.100 / 62. 17.100\n",
      "  libavformat    62.  6.101 / 62.  6.101\n",
      "  libavdevice    62.  2.100 / 62.  2.100\n",
      "  libavfilter    11.  9.100 / 11.  9.100\n",
      "  libswscale      9.  3.100 /  9.  3.100\n",
      "  libswresample   6.  2.100 /  6.  2.100\n",
      "Input #0, matroska,webm, from 'talks_audio\\A Simple Way to Break a Bad Habit é”ï¿½ Judson Brewer é”ï¿½ TED.webm':\n",
      "  Metadata:\n",
      "    encoder         : google/video-file\n",
      "  Duration: 00:09:24.62, start: -0.007000, bitrate: 109 kb/s\n",
      "  Stream #0:0(eng): Audio: opus, 48000 Hz, stereo, fltp, start -0.007000 (default)\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (opus (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'talks_audio\\A Simple Way to Break a Bad Habit é”ï¿½ Judson Brewer é”ï¿½ TED.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf62.6.101\n",
      "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.17.100 pcm_s16le\n",
      "size=   34560KiB time=00:03:04.90 bitrate=1531.2kbits/s speed= 363x elapsed=0:00:00.50    \n",
      "size=   74496KiB time=00:06:38.16 bitrate=1532.7kbits/s speed= 390x elapsed=0:00:01.01    \n",
      "[opus @ 000001bbf2cb48c0] Error parsing Opus packet header.\n",
      "[out#0/wav @ 000001bbf0f19740] video:0KiB audio:105863KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000072%\n",
      "size=  105863KiB time=00:09:24.61 bitrate=1536.0kbits/s speed= 405x elapsed=0:00:01.39    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted talks_audio\\Inside the Mind of a Master Procrastinator ï½œ Tim Urban ï½œ TED.webm â†’ talks_audio\\Inside the Mind of a Master Procrastinator ï½œ Tim Urban ï½œ TED.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-121584-ge59d964a3c-20251101 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (crosstool-NG 1.28.0.1_403899e)\n",
      "  configuration: --prefix=/ffbuild/prefix --pkg-config-flags=--static --pkg-config=pkg-config --cross-prefix=x86_64-w64-mingw32- --arch=x86_64 --target-os=mingw32 --enable-gpl --enable-version3 --disable-debug --enable-shared --disable-static --disable-w32threads --enable-pthreads --enable-iconv --enable-zlib --enable-libxml2 --enable-libvmaf --enable-fontconfig --enable-libharfbuzz --enable-libfreetype --enable-libfribidi --enable-vulkan --enable-libshaderc --enable-libvorbis --disable-libxcb --disable-xlib --disable-libpulse --enable-opencl --enable-gmp --enable-lzma --enable-amf --enable-libaom --enable-libaribb24 --enable-avisynth --enable-chromaprint --enable-libdav1d --enable-libdavs2 --enable-libdvdread --enable-libdvdnav --disable-libfdk-aac --enable-ffnvcodec --enable-cuda-llvm --enable-frei0r --enable-libgme --enable-libkvazaar --enable-libaribcaption --enable-libass --enable-libbluray --enable-libjxl --enable-libmp3lame --enable-libopus --enable-libplacebo --enable-librist --enable-libssh --enable-libtheora --enable-libvpx --enable-libwebp --enable-libzmq --enable-lv2 --enable-libvpl --enable-openal --enable-liboapv --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopenmpt --enable-librav1e --enable-librubberband --enable-schannel --enable-sdl2 --enable-libsnappy --enable-libsoxr --enable-libsrt --enable-libsvtav1 --enable-libtwolame --enable-libuavs3d --disable-libdrm --enable-vaapi --enable-libvidstab --enable-libvvenc --enable-whisper --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libzimg --enable-libzvbi --extra-cflags=-DLIBTWOLAME_STATIC --extra-cxxflags= --extra-libs=-lgomp --extra-ldflags=-pthread --extra-ldexeflags= --cc=x86_64-w64-mingw32-gcc --cxx=x86_64-w64-mingw32-g++ --ar=x86_64-w64-mingw32-gcc-ar --ranlib=x86_64-w64-mingw32-gcc-ranlib --nm=x86_64-w64-mingw32-gcc-nm --extra-version=20251101\n",
      "  libavutil      60. 16.100 / 60. 16.100\n",
      "  libavcodec     62. 17.100 / 62. 17.100\n",
      "  libavformat    62.  6.101 / 62.  6.101\n",
      "  libavdevice    62.  2.100 / 62.  2.100\n",
      "  libavfilter    11.  9.100 / 11.  9.100\n",
      "  libswscale      9.  3.100 /  9.  3.100\n",
      "  libswresample   6.  2.100 /  6.  2.100\n",
      "Input #0, matroska,webm, from 'talks_audio\\Inside the Mind of a Master Procrastinator é”ï¿½ Tim Urban é”ï¿½ TED.webm':\n",
      "  Metadata:\n",
      "    encoder         : google/video-file\n",
      "  Duration: 00:14:03.72, start: -0.007000, bitrate: 123 kb/s\n",
      "  Stream #0:0(eng): Audio: opus, 48000 Hz, stereo, fltp, start -0.007000 (default)\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (opus (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'talks_audio\\Inside the Mind of a Master Procrastinator é”ï¿½ Tim Urban é”ï¿½ TED.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf62.6.101\n",
      "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.17.100 pcm_s16le\n",
      "size=   39680KiB time=00:03:32.30 bitrate=1531.1kbits/s speed= 408x elapsed=0:00:00.51    \n",
      "size=   79360KiB time=00:07:04.12 bitrate=1532.9kbits/s speed= 408x elapsed=0:00:01.04    \n",
      "size=  119296KiB time=00:10:37.28 bitrate=1533.5kbits/s speed= 411x elapsed=0:00:01.55    \n",
      "size=  157184KiB time=00:13:59.00 bitrate=1534.7kbits/s speed= 406x elapsed=0:00:02.06    \n",
      "[opus @ 0000017fa1697640] Error parsing Opus packet header.\n",
      "[out#0/wav @ 0000017f9fcd8a00] video:0KiB audio:158195KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000048%\n",
      "size=  158195KiB time=00:14:03.71 bitrate=1536.0kbits/s speed= 406x elapsed=0:00:02.08    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted talks_audio\\talk1.webm â†’ talks_audio\\talk1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-121584-ge59d964a3c-20251101 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (crosstool-NG 1.28.0.1_403899e)\n",
      "  configuration: --prefix=/ffbuild/prefix --pkg-config-flags=--static --pkg-config=pkg-config --cross-prefix=x86_64-w64-mingw32- --arch=x86_64 --target-os=mingw32 --enable-gpl --enable-version3 --disable-debug --enable-shared --disable-static --disable-w32threads --enable-pthreads --enable-iconv --enable-zlib --enable-libxml2 --enable-libvmaf --enable-fontconfig --enable-libharfbuzz --enable-libfreetype --enable-libfribidi --enable-vulkan --enable-libshaderc --enable-libvorbis --disable-libxcb --disable-xlib --disable-libpulse --enable-opencl --enable-gmp --enable-lzma --enable-amf --enable-libaom --enable-libaribb24 --enable-avisynth --enable-chromaprint --enable-libdav1d --enable-libdavs2 --enable-libdvdread --enable-libdvdnav --disable-libfdk-aac --enable-ffnvcodec --enable-cuda-llvm --enable-frei0r --enable-libgme --enable-libkvazaar --enable-libaribcaption --enable-libass --enable-libbluray --enable-libjxl --enable-libmp3lame --enable-libopus --enable-libplacebo --enable-librist --enable-libssh --enable-libtheora --enable-libvpx --enable-libwebp --enable-libzmq --enable-lv2 --enable-libvpl --enable-openal --enable-liboapv --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopenmpt --enable-librav1e --enable-librubberband --enable-schannel --enable-sdl2 --enable-libsnappy --enable-libsoxr --enable-libsrt --enable-libsvtav1 --enable-libtwolame --enable-libuavs3d --disable-libdrm --enable-vaapi --enable-libvidstab --enable-libvvenc --enable-whisper --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libzimg --enable-libzvbi --extra-cflags=-DLIBTWOLAME_STATIC --extra-cxxflags= --extra-libs=-lgomp --extra-ldflags=-pthread --extra-ldexeflags= --cc=x86_64-w64-mingw32-gcc --cxx=x86_64-w64-mingw32-g++ --ar=x86_64-w64-mingw32-gcc-ar --ranlib=x86_64-w64-mingw32-gcc-ranlib --nm=x86_64-w64-mingw32-gcc-nm --extra-version=20251101\n",
      "  libavutil      60. 16.100 / 60. 16.100\n",
      "  libavcodec     62. 17.100 / 62. 17.100\n",
      "  libavformat    62.  6.101 / 62.  6.101\n",
      "  libavdevice    62.  2.100 / 62.  2.100\n",
      "  libavfilter    11.  9.100 / 11.  9.100\n",
      "  libswscale      9.  3.100 /  9.  3.100\n",
      "  libswresample   6.  2.100 /  6.  2.100\n",
      "Input #0, matroska,webm, from 'talks_audio\\talk1.webm':\n",
      "  Metadata:\n",
      "    encoder         : google/video-file\n",
      "  Duration: 00:09:24.62, start: -0.007000, bitrate: 109 kb/s\n",
      "  Stream #0:0(eng): Audio: opus, 48000 Hz, stereo, fltp, start -0.007000 (default)\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (opus (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'talks_audio\\talk1.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf62.6.101\n",
      "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.17.100 pcm_s16le\n",
      "size=   38656KiB time=00:03:27.14 bitrate=1528.8kbits/s speed= 400x elapsed=0:00:00.51    \n",
      "size=   78592KiB time=00:06:59.94 bitrate=1533.1kbits/s speed= 405x elapsed=0:00:01.03    \n",
      "[opus @ 000001781a9957c0] Error parsing Opus packet header.\n",
      "[out#0/wav @ 0000017818b38700] video:0KiB audio:105863KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000072%\n",
      "size=  105863KiB time=00:09:24.61 bitrate=1536.0kbits/s speed= 409x elapsed=0:00:01.38    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted talks_audio\\talk2.webm â†’ talks_audio\\talk2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-121584-ge59d964a3c-20251101 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 15.2.0 (crosstool-NG 1.28.0.1_403899e)\n",
      "  configuration: --prefix=/ffbuild/prefix --pkg-config-flags=--static --pkg-config=pkg-config --cross-prefix=x86_64-w64-mingw32- --arch=x86_64 --target-os=mingw32 --enable-gpl --enable-version3 --disable-debug --enable-shared --disable-static --disable-w32threads --enable-pthreads --enable-iconv --enable-zlib --enable-libxml2 --enable-libvmaf --enable-fontconfig --enable-libharfbuzz --enable-libfreetype --enable-libfribidi --enable-vulkan --enable-libshaderc --enable-libvorbis --disable-libxcb --disable-xlib --disable-libpulse --enable-opencl --enable-gmp --enable-lzma --enable-amf --enable-libaom --enable-libaribb24 --enable-avisynth --enable-chromaprint --enable-libdav1d --enable-libdavs2 --enable-libdvdread --enable-libdvdnav --disable-libfdk-aac --enable-ffnvcodec --enable-cuda-llvm --enable-frei0r --enable-libgme --enable-libkvazaar --enable-libaribcaption --enable-libass --enable-libbluray --enable-libjxl --enable-libmp3lame --enable-libopus --enable-libplacebo --enable-librist --enable-libssh --enable-libtheora --enable-libvpx --enable-libwebp --enable-libzmq --enable-lv2 --enable-libvpl --enable-openal --enable-liboapv --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopenmpt --enable-librav1e --enable-librubberband --enable-schannel --enable-sdl2 --enable-libsnappy --enable-libsoxr --enable-libsrt --enable-libsvtav1 --enable-libtwolame --enable-libuavs3d --disable-libdrm --enable-vaapi --enable-libvidstab --enable-libvvenc --enable-whisper --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libzimg --enable-libzvbi --extra-cflags=-DLIBTWOLAME_STATIC --extra-cxxflags= --extra-libs=-lgomp --extra-ldflags=-pthread --extra-ldexeflags= --cc=x86_64-w64-mingw32-gcc --cxx=x86_64-w64-mingw32-g++ --ar=x86_64-w64-mingw32-gcc-ar --ranlib=x86_64-w64-mingw32-gcc-ranlib --nm=x86_64-w64-mingw32-gcc-nm --extra-version=20251101\n",
      "  libavutil      60. 16.100 / 60. 16.100\n",
      "  libavcodec     62. 17.100 / 62. 17.100\n",
      "  libavformat    62.  6.101 / 62.  6.101\n",
      "  libavdevice    62.  2.100 / 62.  2.100\n",
      "  libavfilter    11.  9.100 / 11.  9.100\n",
      "  libswscale      9.  3.100 /  9.  3.100\n",
      "  libswresample   6.  2.100 /  6.  2.100\n",
      "Input #0, matroska,webm, from 'talks_audio\\talk2.webm':\n",
      "  Metadata:\n",
      "    encoder         : google/video-file\n",
      "  Duration: 00:14:03.72, start: -0.007000, bitrate: 123 kb/s\n",
      "  Stream #0:0(eng): Audio: opus, 48000 Hz, stereo, fltp, start -0.007000 (default)\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (opus (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'talks_audio\\talk2.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf62.6.101\n",
      "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.17.100 pcm_s16le\n",
      "size=   38144KiB time=00:03:24.78 bitrate=1525.9kbits/s speed= 398x elapsed=0:00:00.51    \n",
      "size=   74752KiB time=00:06:39.50 bitrate=1532.8kbits/s speed= 386x elapsed=0:00:01.03    \n",
      "size=  110592KiB time=00:09:50.34 bitrate=1534.7kbits/s speed= 381x elapsed=0:00:01.54    \n",
      "size=  149760KiB time=00:13:18.86 bitrate=1535.7kbits/s speed= 387x elapsed=0:00:02.06    \n",
      "[opus @ 0000025129725c00] Error parsing Opus packet header.\n",
      "[out#0/wav @ 000002512798a740] video:0KiB audio:158195KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000048%\n",
      "size=  158195KiB time=00:14:03.71 bitrate=1536.0kbits/s speed= 386x elapsed=0:00:02.18    \n"
     ]
    }
   ],
   "source": [
    "# Optional: convert to .wav\n",
    "for f in os.listdir(audio_folder):\n",
    "    if f.lower().endswith((\".m4a\", \".webm\")):\n",
    "        src = os.path.join(audio_folder, f)\n",
    "        dst = os.path.splitext(src)[0] + \".wav\"\n",
    "        !ffmpeg -y -i \"{src}\" \"{dst}\"\n",
    "        print(f\"Converted {src} â†’ {dst}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210308c7-3567-4037-9655-c0d08f76f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !where ffmpeg\n",
    "# !ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8376a3c-1899-4f6c-a7e8-2b6a6823467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import whisper\n",
    "\n",
    "# model = whisper.load_model(\"base\")\n",
    "\n",
    "# audio_files = [os.path.join(audio_folder, f) for f in os.listdir(audio_folder)\n",
    "#                if f.lower().endswith(( \".webm\"))]\n",
    "#                # ((\".mp3\", \".m4a\", \".wav\", \".webm\"))]\n",
    "\n",
    "# for audio_path in audio_files:\n",
    "#     print(\"Transcribing:\", audio_path)\n",
    "#     result = model.transcribe(audio_path)\n",
    "#     print(result[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c673b71-51c6-49d3-a0a4-d847fad9c9ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing audio: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [03:53<00:00, 116.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# Step 3 â€” ASR transcription with Whisper\n",
    "model = whisper.load_model(\"base\")  # you can use \"small\", \"medium\", or \"large\"\n",
    "\n",
    "audio_files = list(Path(audio_folder).glob(\"*.*\"))\n",
    "transcripts = []\n",
    "\n",
    "for audio_path in tqdm(audio_files, desc=\"Transcribing audio\"):\n",
    "    result = model.transcribe(str(audio_path))\n",
    "    \n",
    "    # Collect segments with timestamps\n",
    "    for segment in result['segments']:\n",
    "        transcripts.append({\n",
    "            \"file\": audio_path.name,\n",
    "            \"start\": segment['start'],\n",
    "            \"end\": segment['end'],\n",
    "            \"text\": segment['text']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf7e739-e916-460b-b32d-bdf768115e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9caf37f3-b262-4494-b5a5-bdb0cc458ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 â€” Optional: OCR from video frames / slides\n",
    "import cv2\n",
    "\n",
    "def extract_frames(video_path, every_n_seconds=5):\n",
    "    \"\"\"Yield frames from video every n seconds.\"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = 0\n",
    "    frames = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % int(fps*every_n_seconds) == 0:\n",
    "            frames.append(frame)\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# Example OCR extraction\n",
    "import numpy as np\n",
    "\n",
    "ocr_texts = []\n",
    "for video_file in Path(video_folder).glob(\"*.mp4\"):\n",
    "    frames = extract_frames(video_file, every_n_seconds=5)\n",
    "    for frame in frames:\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        if text.strip():\n",
    "            ocr_texts.append({\n",
    "                \"video_file\": video_file.name,\n",
    "                \"ocr_text\": text.strip()\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c581b3d3-5d33-4e69-8b87-391f6a568248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved transcripts to talks_transcripts.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Step 5 â€” Save transcripts + OCR to JSONL\n",
    "output_file = \"talks_transcripts.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    # save ASR segments\n",
    "    for seg in transcripts:\n",
    "        f.write(json.dumps({\"type\": \"asr\", **seg}, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    # save OCR segments\n",
    "    for ocr in ocr_texts:\n",
    "        f.write(json.dumps({\"type\": \"ocr\", **ocr}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Saved transcripts to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ff696-2dca-4a1f-bb90-56b3d1afcbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 4 is essentially a post-processing / data cleaning pipeline that consolidates everything you did in Tasks 1â€‘3. \n",
    "Letâ€™s break it down carefully and outline a lightweight, robust Jupyter-friendly implementation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a27dc-2255-4bb6-9376-238ce9417902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 â€” Prerequisites\n",
    "# pip install langdetect datasketch tqdm regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44b3c84c-bb89-464d-8c22-b3758e39c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 â€” Merge all task outputs\n",
    "import json\n",
    "import os\n",
    "\n",
    "corpus = []\n",
    "\n",
    "# Task 1\n",
    "with open(\"arxiv_clean.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus.extend(json.load(f))  # expects list of {url, title, abstract, authors, date}\n",
    "\n",
    "# Task 2\n",
    "pdf_folder = \"pdf_ocr\"\n",
    "for fname in os.listdir(pdf_folder):\n",
    "    if fname.endswith(\".txt\"):\n",
    "        with open(os.path.join(pdf_folder, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        corpus.append({\"source\": fname, \"text\": text})\n",
    "\n",
    "# Task 3\n",
    "with open(\"talks_transcripts.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        corpus.append({\"source\": \"talk\", **json.loads(line)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da16f608-c5b2-4fe4-b3b9-1b8775eb5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 â€” Language Detection\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0  # deterministic\n",
    "\n",
    "for doc in corpus:\n",
    "    try:\n",
    "        doc[\"lang\"] = detect(doc.get(\"text\", doc.get(\"abstract\", \"\")))\n",
    "    except:\n",
    "        doc[\"lang\"] = \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4346120a-0e3c-464e-81bf-d38ca9a53fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 â€” Remove HTML / noise\n",
    "import re\n",
    "\n",
    "def clean_html(text):\n",
    "    # remove HTML tags\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "    # remove multiple spaces/newlines\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "for doc in corpus:\n",
    "    field = \"text\" if \"text\" in doc else \"abstract\"\n",
    "    doc[field] = clean_html(doc[field])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4418b4b-badc-4d34-b20d-b75465b2a806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicated: 468 / 479\n"
     ]
    }
   ],
   "source": [
    "# Step 4 â€” Deduplication with MinHash\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "threshold = 0.7  # similarity threshold\n",
    "lsh = MinHashLSH(threshold=threshold, num_perm=128)\n",
    "\n",
    "minhashes = []\n",
    "unique_docs = []\n",
    "\n",
    "for i, doc in enumerate(corpus):\n",
    "    field = \"text\" if \"text\" in doc else \"abstract\"\n",
    "    words = set(doc[field].split())\n",
    "    m = MinHash(num_perm=128)\n",
    "    for w in words:\n",
    "        m.update(w.encode(\"utf-8\"))\n",
    "    minhashes.append(m)\n",
    "    # query LSH for duplicates\n",
    "    if i == 0:\n",
    "        unique_docs.append(doc)\n",
    "        lsh.insert(str(i), m)\n",
    "    else:\n",
    "        if not lsh.query(m):\n",
    "            unique_docs.append(doc)\n",
    "            lsh.insert(str(i), m)\n",
    "\n",
    "print(f\"Deduplicated: {len(unique_docs)} / {len(corpus)}\")\n",
    "corpus = unique_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3d38cbf-551a-4afa-afd9-4de51e6546a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 â€” Remove PII\n",
    "pii_patterns = [\n",
    "    r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\",  # emails\n",
    "    r\"\\b(?:\\d[ -]*?){13,16}\\b\",                          # credit cards\n",
    "    r\"\\b(?:\\+?\\d{1,3}[ -]?)?(?:\\(?\\d{2,3}\\)?[ -]?)?\\d{3,4}[ -]?\\d{3,4}\\b\"  # phone numbers\n",
    "]\n",
    "\n",
    "pii_removed_count = 0\n",
    "\n",
    "def remove_pii(text):\n",
    "    global pii_removed_count\n",
    "    for pat in pii_patterns:\n",
    "        matches = re.findall(pat, text)\n",
    "        pii_removed_count += len(matches)\n",
    "        text = re.sub(pat, \"[REDACTED]\", text)\n",
    "    return text\n",
    "    \n",
    "# def remove_pii(text):\n",
    "#     for pat in pii_patterns:\n",
    "#         text = re.sub(pat, \"[REDACTED]\", text)\n",
    "#     return text\n",
    "\n",
    "for doc in corpus:\n",
    "    field = \"text\" if \"text\" in doc else \"abstract\"\n",
    "    doc[field] = remove_pii(doc[field])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2e06230-9062-41a5-a123-a03dc794a047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "print(pii_removed_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8b59945-048f-42c0-85a8-0db5aed9ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetitive n-grams removed: 7\n"
     ]
    }
   ],
   "source": [
    "# Step 6 â€” Remove repetitive nâ€‘grams\n",
    "# For example, remove trigrams repeated consecutively:\n",
    "repetitive_ngrams_removed = 0\n",
    "def remove_repetitive_ngrams(text, n=3):\n",
    "    global repetitive_ngrams_removed\n",
    "    tokens = text.split()\n",
    "    cleaned = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        ngram = tokens[i:i+n]\n",
    "        # check next n tokens\n",
    "        if i+n*2 <= len(tokens) and tokens[i+n:i+n*2] == ngram:\n",
    "            repetitive_ngrams_removed += 1\n",
    "            i += n  # skip repetition\n",
    "        else:\n",
    "            cleaned.append(tokens[i])\n",
    "            i += 1\n",
    "    return \" \".join(cleaned)\n",
    "\n",
    "for doc in corpus:\n",
    "    field = \"text\" if \"text\" in doc else \"abstract\"\n",
    "    doc[field] = remove_repetitive_ngrams(doc[field])\n",
    "\n",
    "print(f\"Repetitive n-grams removed: {repetitive_ngrams_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d1b0b11-8b3b-412b-8fab-11a282a3f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 468\n",
      "Total tokens: 114161\n"
     ]
    }
   ],
   "source": [
    "# Step 7 â€” Save cleaned corpus & stats\n",
    "# Save\n",
    "def get_text(doc):\n",
    "    if \"text\" in doc:\n",
    "        return doc[\"text\"]\n",
    "    elif \"abstract\" in doc:\n",
    "        return doc[\"abstract\"]\n",
    "    else:\n",
    "        return \"\"  # fallback empty\n",
    "\n",
    "# Save cleaned corpus\n",
    "with open(\"clean_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for doc in corpus:\n",
    "        text = get_text(doc)\n",
    "        if text:  # only write non-empty\n",
    "            f.write(text + \"\\n\\n\")\n",
    "\n",
    "# Compute stats\n",
    "total_tokens = sum(len(get_text(doc).split()) for doc in corpus)\n",
    "total_docs = len(corpus)\n",
    "print(f\"Total documents: {total_docs}\")\n",
    "print(f\"Total tokens: {total_tokens}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8e95e-efb4-4cfd-973a-891d79c91cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
